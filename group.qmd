---
title: "Group Task"
author:
  - "Marco Boso 100535153"
  - "Diego Paroli 100554973"
  - "Yijia Lin 100452242"
  - "Bradley McKenzie 100535241"
  - "Linghan Zheng 100540803"
  - "Jia Lin 100536210"
  - "Isabel Monge 100542532"
format:
  html:
    theme: [style.scss]
    toc: true
    toc-location: right
    toc-title: Índice
    embed-resources: true
---

## Objectives and mandatory items

The objective of the delivery is to perform an analysis of the electoral data, carrying out the debugging, summaries and graphs you consider, both of their results and the accuracy of the electoral polls.

Specifically, **you must work only in the time window that includes the elections from 2008 to the last elections of 2019**.

### General comments

In addition to what you see fit to execute, the following items are mandatory:

-   Each group should **present before 9th January (23:59) an analysis of the data** in `.qmd` and `.html` format in **Quarto slides** mode, which **will be the ones they will present on the day of the presentation**.

-   **Quarto slides should be uploaded to Github** (the link should be provided by a member of each group).

-   The **maximum number of slides** should be 40. The **maximum time for each group** will be 20-22 minutes (+5 minutes for questions).

-   During the presentation you will **explain (summarised!) the analysis performed** so that **each team member speaks for a similar amount of time** and **each member can be asked about any of the steps**. The grade does not have to be the same for all members.

-   It will be valued not only the content but also the container (aesthetics).

-   The **objective is to demonstrate that the maximum knowledge of the course has been acquired**: the more content of the syllabus is included, the better.

### Mandatory items:

1.  Data should be **converted to tidydata** where appropriate.

2.  You should **include at least one join** between tables.

3.  Reminder: information = variance, so **remove columns that are not going to contribute anything**.

4.  The **glue and lubridate** packages should be used at some point, as well as the **forcats**. The use of **ggplot2** will be highly valued.

5.  The following should be used at least once:

    -   mutate
    -   summarise
    -   group_by (or equivalent)
    -   case_when

6.  We have many, many parties running for election. **We will only be interested in the following parties**:

    -   PARTIDO SOCIALISTA OBRERO ESPAÑOL (beware: it has/had federations - branches - with some other name).
    -   PARTIDO POPULAR
    -   CIUDADANOS (caution: has/had federations - branches - with some other name)
    -   PARTIDO NACIONALISTA VASCO
    -   BLOQUE NACIONALISTA GALLEGO
    -   CONVERGÈNCIA I UNIÓ
    -   UNIDAS PODEMOS - IU (beware that here they have had various names - IU, podem, ezker batua, ...- and have not always gone together, but here we will analyze them together)
    -   ESQUERRA REPUBLICANA DE CATALUNYA
    -   EH - BILDU (are now a coalition of parties formed by Sortu, Eusko Alkartasuna, Aralar, Alternatiba)
    -   MÁS PAÍS
    -   VOX

7.  Anything other than any of the above parties should be imputed as "OTHER". Remember to add properly the data after the previous recoding.

8.  Party acronyms will be used for the visualizations. The inclusion of graphics will be highly valued (see <https://r-graph-gallery.com/>).

9.  You must use all 4 data files at some point.

10. You must define at least one (non-trivial) function of your own.

11. You will have to discard mandatory polls that:

```         
-   refer to elections before 2008
-   that are exit polls
-   have a sample size of less than 750 or are unknown
-   that have less than 1 or less fieldwork days
```

12. You must obligatorily answer the following questions (plus those that you consider analyzing to distinguish yourself from the rest of the teams, either numerically and/or graphically)

```         
-   Which party was the winner in the municipalities with more than 100,000 habitants (census) in each of the elections?
-   Which party was the second when the first was the PSOE? And when the first was the PP?
-   Who benefits from low turnout?
-   How to analyze the relationship between census and vote? Is it true that certain parties win in rural areas?
-   How to calibrate the error of the polls (remember that the polls are voting intentions at national level)?
-   Which polling houses got it right the most and which ones deviated the most from the results?
```

**You should include at least 3 more "original" questions** that you think that it could be interesting to be answer with the data.

### Marks

**The one who does the most things will not be valued the most**. More is not always better. The **originality** (with respect to the rest of the works, for example in the analyzed or in the subject or ...) of what has been proposed, in the handling of tables (or in the visualization), the **caring** put in the delivery (care in life is important) and the **relevance** of what has been done will be valued. Once you have the mandatory items with your database more or less completed, **think before** chopping code: what could be interesting? What do I need to get a summary both numerical and visual?

Remember that the real goal is to demonstrate a mastery of the tools seen throughout the course. And that happens not only by the quantity of them used but also by the quality when executing them.

**Some dataviz will be extremely positive valued**.

## Required packages

> Insert in the lower chunk the packages you will need

```{r}
rm(list = ls())
library(tidyverse)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(DataExplorer)
library(glue)
```

## Data

The practice will be based on the **electoral data archives** below, compiling data on elections to the Spanish Congress of Deputies from 2008 to the present, as well as surveys, municipalities codes and abbreviations.

```{r}
# NO TOQUES NADA
election_data <- read_csv(file = "./data/datos_elecciones_brutos.csv")
cod_mun <- read_csv(file = "./data/cod_mun.csv")
surveys <- read_csv(file = "./data/historical_surveys.csv")
abbrev <- read_csv(file = "./data/siglas.csv")
```

The data will be as follows:

-   `election_data`: file with election data for Congress from 2018 to the last ones in 2019.

    -   `tipo_eleccion`: type of election (02 if congressional election)
    -   `anno`, `mes`: year and month of elections
    -   `vuelta`: electoral round (1 if first round)
    -   `codigo_ccaa, codigo_provincia, codigo_municipio, codigo_distrito_electoral`: code of the ccaa, province, municipality and electoral district.
    -   `numero_mesas`: number of polling stations
    -   `censo`: census
    -   `participacion_1, participacion_2`: participation in the first preview (14:00) and second preview (18:00) before polls close (20:00)
    -   `votos_blancos`: blank ballots
    -   `votos_candidaturas`: party ballots
    -   `votos_nulos`: null ballots
    -   ballots for each party

-   `cod_mun`: file with the codes and names of each municipality

-   `abbrev`: acronyms and names associated with each party

-   `surveys`: table of electoral polls since 1982. Some of the variables are the following:

    -   `type_survey`: type of survey (national, regional, etc.)
    -   `date_elec`: date of future elections
    -   `id_pollster`, `pollster`, `media`: id and name of the polling company, as well as the media that commissioned it.
    -   `field_date_from`, `field_date_to`: start and end date of fieldwork
    -   `exit_poll`: whether it is an exit poll or not
    -   `size`: sample size
    -   `turnout`: turnout estimate
    -   estimated voting intentions for the main parties

### Cleaning the data -- surveys

```{r cleaning survey df}

# Filter dataset
cleaned_surveys <- surveys |>
  mutate(
    # Parse dates variables as date objects
    field_date_from = ymd(field_date_from),
    field_date_to = ymd(field_date_to),
    date_elec = ymd(date_elec),
    # Calculate the number of fieldwork days
    fieldwork_days = as.numeric(field_date_to - field_date_from + 1)
  ) |>
  filter(
    !exit_poll,                           # Exclude exit polls
    date_elec >= ymd("2008-01-01"),       # Exclude polls referred to elections before 2008
    size >= 750,                          # Exclude polls with sample size < 750
    fieldwork_days > 1                    # Exclude polls with 1 or fewer fieldwork days
  )

# Deleting columns that only have NAs
cleaned_surveys <- cleaned_surveys |> 
  select(where(~ !all(is.na(.))))

# Identify party columns dynamically
metadata_columns <- c("type_survey", "date_elec", "id_pollster", "pollster", "media",
                      "field_date_from", "field_date_to", "fieldwork_days", "exit_poll", 
                      "size", "turnout")
party_columns <- setdiff(colnames(cleaned_surveys), metadata_columns)

# Reshape data into long format
tidy_surveys <- cleaned_surveys |>
  pivot_longer(
    cols = all_of(party_columns),  # Reshape party columns
    names_to = "party_raw",        # Raw party names
    values_to = "votes"            # Corresponding voting intentions
  )

# add on party names by code
tidy_surveys <- tidy_surveys %>%
  mutate(
    party = case_when(
      party_raw == "PSOE" ~ "PARTIDO SOCIALISTA OBRERO ESPAÑOL",
      party_raw == "CIU" ~ "CONVERGÈNCIA I UNIÓ",
      party_raw == "EAJ-PNV" ~ "PARTIDO NACIONALISTA VASCO",
      party_raw == "ERC" ~ "ESQUERRA REPUBLICANA DE CATALUNYA",
      party_raw == "IU" ~ "UNIDAS PODEMOS - IU",
      party_raw == "PP" ~ "PARTIDO POPULAR",
      party_raw == "BNG" ~ "BLOQUE NACIONALISTA GALLEGO",
      party_raw == "CS" ~ "CIUDADANOS",
      party_raw == "EH-BILDU" ~ "EH - BILDU",
      party_raw == "PODEMOS" ~ "UNIDAS PODEMOS - IU",
      party_raw == "VOX" ~ "VOX",
      party_raw == "MP" ~ "MÁS PAÍS",
      TRUE ~ "OTHER")
  )

# Create a column for proper, unqique acronyms
tidy_surveys <- tidy_surveys |> 
  mutate(
    party_code = case_when(
      party == "UNIDAS PODEMOS - IU"~ "PODEMOS-IU",
      party == "OTHER"~ "OTHER",
      TRUE ~ party_raw)
  )

# Select relevant columns
# Getting rid of type_survey, exit_poll (take only 1 value), party_raw
final_surveys <- tidy_surveys |>
  select(-type_survey, -exit_poll, -party_raw) |> 
  relocate(fieldwork_days, .after = field_date_to) |> 
  relocate(votes, .after = party_code) 

# Summing all votes based on the party reclassification
final_surveys <- final_surveys |> 
  group_by(across(-votes)) |> 
  summarize(votes = sum(votes, na.rm = TRUE), .groups = "drop") |> 
  arrange(field_date_from)
# We have 1614 surveys (rows from cleaned_surveys), 12 parties (meaning 12 rows per survey). Thus 1614x12=19368 rows

# Preview
final_surveys
```

### Creating table for party codes

Creating a table to link each party name to its unique code

```{r}
party_info <- final_surveys |> 
  select(party, party_code) |> 
  unique()
```

### Cleaning the data -- election_data

The election_data file is large and requires quite extensive cleaning to make it "tidy". We will tidy the data to try make it most useful for future analysis. The election data starts off with 48,737 rows and 471 columns. Reducing the number of columns is a clear priority.

First, we look at the quality of the data and see if any information is redundant and can be removed.

```{r check-electiondata-quality}
plot_intro(election_data)

# We see 1.9% missing colums, identify the cols with no data - we have 9 cols. 
blank_cols <- names(election_data)[sapply(election_data, function(x) all(is.na(x)))]

# Drop these columns and also filter to ensure no info outside 2008 to 2019 is included. 
election_data <- election_data |> 
  select(-all_of(blank_cols)) |> 
  filter(anno >= 2008 & anno <= 2019)

# Drop columns that are logical
election_data <- election_data %>%
  select(where(~ !is.logical(.)))
```

```{r}
# See the improvements
plot_intro(election_data)
```

Second, we begin to make the election data tidy. We start by pivoting the data so all columns for party names are within one "party" variable. Before this we have 414 columns referring to parties.

```{r pivot-election}
# Pivot all the party names and ballot counts to the main table
election_pivot <- election_data |> 
  pivot_longer(
    cols = `BERDEAK-LOS VERDES`:`COALICIÓN POR MELILLA`, # select all party data
    names_to = "party",
    values_to = "ballots"
  )
str(election_pivot)
head(election_pivot)
```

We now have a table with 20,177,118 rows and 17 columns.

This is more clean than previously, but we still need to aggregate of our party variables into the main party groups. We will do this by creating a mapping table (party_names) that standardizes the raw party names into main party groupings (party_main) using regular expressions.

```{r assigning-partygroup}
party_names <- tibble(names = unique(election_pivot$party))

# Party names in the election_data file do not match up perfectly with the abbrev file (i.e. some of the names present in party_names are not in abbrev)
# So it is better to work directly on party_names instead of using abbrev

party_names <- party_names |> 
    mutate(party_main = case_when(
                str_detect(names, "(?i)PSOE|PARTIDO DOS SOCIALISTAS DE GALICIA|PARTIDO SOCIALISTA DE EUSKADI|PARTIDO SOCIALISTA OBRERO ESPAÑOL|PARTIT SOCIALISTA OBRER ESPANYOL|PARTIT DELS SOCIALISTES DE CATALUNYA") ~ "PARTIDO SOCIALISTA OBRERO ESPAÑOL",
                str_detect(names, "(?i)PARTIDO POPULAR") ~ "PARTIDO POPULAR",
                str_detect(names, "(?i)CIUDADANOS-PARTIDO DE LA CIUDADANIA|CIUDADANOS-PARTIDO DE LA CIUDADANÍA|CIUDADANOS PARTIDO DE LA CIUDADANIA|CIUDADANOS PARTIDO DE LA CIUDADANÍA|CIUDADANOS, PARTIDO DE LA CIUDADANÍA|CIUTADANS") ~ "CIUDADANOS",
                str_detect(names, "(?i)EUZKO ALDERDI JELTZALEA-PARTIDO NACIONALISTA VASCO") ~ "PARTIDO NACIONALISTA VASCO",
                str_detect(names, "(?i)BLOQUE NACIONALISTA GALEGO|BNG") ~ "BLOQUE NACIONALISTA GALLEGO",
                str_detect(names, "(?i)CONVERGENCIA I UNIO|CONVERGÈNCIA I UNIÓ") ~ "CONVERGÈNCIA I UNIÓ",
                str_detect(names, "(?i)PODEM|EZKER BATUA|EZKER ANITZA|IZQUIERDA UNIDA|ESQUERRA UNIDA|ESQUERDA UNIDA") ~ "UNIDAS PODEMOS - IU",
                str_detect(names, "(?i)ESQUERRA REPUBLICANA") ~ "ESQUERRA REPUBLICANA DE CATALUNYA",
                str_detect(names, "(?i)BILDU|EUSKO ALKARTASUNA|ARALAR|SORTU|ALTERNATIBA") ~ "EH - BILDU",
                str_detect(names, "(?i)MÁS PAÍS") ~ "MÁS PAÍS",
                str_detect(names, "(?i)VOX") ~ "VOX",
                TRUE ~ "OTHER")
    )

unique(party_names$party_main)

# Adding party code to party_names dataframe
party_names <- party_names |> 
  left_join(party_info, by = join_by(party_main == party))
```

Now join on the main party names and codes to our election table. Testing was undertaken and the join of a table was more efficient than alternatives (e.g. str_detects over election_pivot or rowwise summaries).

```{r join-partygroup}
# Join party main and party code into main df
election_pivot <- election_pivot |> 
  left_join(party_names, by = join_by(party == names))
```

Now we will include some additional information that will make the analysis potentially easier later, including province and total votes counts from our data:

```{r join-municipality-names}
# Create municipal code to join on municipal names. 
# Create total votes column
election_pivot <- election_pivot |>
  mutate(cod_mun = paste(codigo_ccaa, codigo_provincia, codigo_municipio, sep="-"),
         total_votes = votos_blancos + votos_nulos + votos_candidaturas)

# Join municipality names
election_pivot <- election_pivot |> 
  left_join(cod_mun, by = join_by(cod_mun))  

# Check quality of the join and whether NA's have been introduced as municipality names
any(is.na(election_pivot$municipio))
```

Be careful not all 8135 municipalities appear in each election. We have 6 elections and 414 parties, thus we should have 6x414=2484 occurrences for each municipality, but that is not the case.

Also be careful some municipalities have the same name (but different mun_code), so if you ever need to group by municipality remember to group by mun_code instead of municipality.

```{r}
# Count the number of times each municipaly appears and then get the unique values for that count (not all are 2484) meaning some municipalities are not present in certain elections
election_pivot |> count(cod_mun) |> pull(n) |> unique()

#Number of unique values for cod_mun is different than number of unique values for municipio
n_distinct(cod_mun$cod_mun)
n_distinct(cod_mun$municipio)
```

Now we need to group together all of the votes for "OTHER" variables and create unique identifiers for each individual election in our dataframes.

Currently we have a table of 22 variables with 20,177,118 rows. We can clean this more.

First, identify the redundant data in our election. We can remove:

tipo_eleccion - because all values = 02. It is not useful vuelta = because all values = 1, it is not useful. geographic variables = we will remove `codigo_municipio` is included in `cod_mun` which we joined on from the *cod_mun* table. We keep the autonomous community and proivnce variables for potential future aggregation and analysis. codigo_distrito_electoral - because every value is zero. It is not useful.

Notably, we have many NA ballot rows and a row for each individual party at each election, where will also try to reduce this when we aggregate the party data with the "party_main" variable created.

```{r tidy-election-selecting-variables}
# To clean the data more, reduce our dataset and rename key variables so everything is more consistent in English
tidy_election <- election_pivot |> 
  select(year = anno, 
         month = mes,
         code_community = codigo_ccaa,
         code_province = codigo_provincia,
         code_municipality = cod_mun,
         municipality = municipio,
         population = censo,
         polling_stations = numero_mesas,
         participation_1 = participacion_1,
         participation_2 = participacion_2,
         blank_votes = votos_blancos,
         null_votes = votos_nulos,
         valid_votes = votos_candidaturas,
         total_votes,
         party_main,
         party_code,
         ballots)

summary(tidy_election)
```

```{r tidy-election-aggregating parties}
tidy_election <- tidy_election |> 
  group_by(across(-ballots))|> 
  summarise(party_ballots = sum(ballots, na.rm=TRUE), .groups = "drop")

tidy_election
```

Joining year and month into one variable

```{r creating-date-variable}
final_election <- tidy_election |> 
  mutate(date_elec = glue("{year}-{month}-01")) |> 
  relocate(date_elec, .before = year) |> 
  select(-year, -month)

#Adding correct days to match survey dataframe
final_election <- final_election |> 
  mutate(
    date_elec = ymd(case_when(
      date_elec == "2008-03-01" ~ "2008-03-09",
      date_elec == "2011-11-01" ~ "2011-11-20",
      date_elec == "2015-12-01" ~ "2015-12-20",
      date_elec == "2016-06-01" ~ "2016-06-26",
      date_elec == "2019-04-01" ~ "2019-04-28",
      date_elec == "2019-11-01" ~ "2019-11-10"))
  )

str(final_election)
```

Election identifiers:

-   Timing -\> date
-   Area information -\> code_community (autonomous community), code_province, code_municipality, municipality, population
-   General election information -\> polling_stations, participation_1, participation_2, blank_votes, null_votes, valid_votes, total_votes
-   Party votes received -\> party_main, party_code, party_ballots

### Creating turnout dataframe

Creating a dataframe storing all the turnout data for each municipality in each election in case we need to work just on turnout or other data that does not change by party.

All this info is still included in final_election

```{r}
turnout <- final_election |> 
  select(
    date_elec, code_community, code_province, code_municipality, municipality,
    population, polling_stations, participation_1, participation_2, 
    blank_votes, null_votes, valid_votes, total_votes
  ) |> 
  distinct()
turnout
```

### Recap cleaning

We have 2 primary datasets at this stage, election data and survey data, plus a turnout dataframe which is a subset of the election data. For surveys, the data has been cleaned so each row represents the votes for one party within a specific national poll. For elections, the data has been cleaned so each row represents the number of votes for a party within an election in a specific municipality.

The `final_surveys` data includes:

-   election date, pollster and media information, fieldwork dates
-   size of the survey and turnout
-   party name, party code
-   votes received (for that party in that poll)

The `final_election` data includes:

-   date of the election
-   party name, party code (with non-primary parties grouped)
-   identifier for autonomous community, province and municipality
-   municipality population
-   election information such as number of polling stations, votes per session
-   ballots received (for that party per election in each municipality)

The `turnout` data includes:

-   information on the number of votes and type of vote (e.g. valid or blank/null) per municipality in each election.

**!!!!!!! WORK ON DATAFRAMES final_surveys, final_election, turnout !!!!!!!**\
**!!!!!!! DO NOT OVERWRITE THESE DATAFRAMES, CREATE NEW ONES IF YOU NEED TO MODIFY THEM (ex. surveys_q1 \<- final_surveys) !!!!!!!**

## Mandatory questions

### 1.Which party was the winner in the municipalities with more than 100,000 habitants (census) in each of the elections?

We create a table `(winning_table)` here that has a column listing each municipality that reported over 100k habitants for at least one election. Then there are columns for each of the elections that report on who won the election and the % of total vote the winning party received. 

First, explore the data and see that 48 of the 8,135 municipalities had over 100k people. We use code_municipality as some municipalities have the same name. 

```{r}
# count of provinces to include (for checking)
final_election |> 
  filter(population >100000) |> 
  summarise(num_100k = length(unique(code_municipality))) # we have 48 municipalities 

# create table to identify winning party only in provinces >100k
winners100k <- final_election |> 
  filter(population > 100000) |> 
  group_by(date_elec, code_municipality, municipality) |> 
  mutate(vote_percent = as.character(glue("{party_main} ({round(party_ballots/valid_votes*100, 1)}%)"))) |> # create name + vote% value. 
  slice_max(order_by = party_ballots, n = 1) |> #select winner only
  ungroup() |> 
  select(date_elec, code_municipality, municipality, population, party_main, party_code, valid_votes, party_ballots, vote_percent)


# Pivot to create summary table of only the municipality, winner and vote getting %
winning_table <- winners100k |> 
  select(municipality, date_elec, vote_percent) |> 
  pivot_wider(names_from = date_elec, 
              values_from = vote_percent)

# print output
winning_table
```

Some of our winning table, have NA values, we confirm that this is because there code was <100k in some elections and over 100k in others:

```{r}
# Check why some have NA's - pull municipality names
varying_pop_municips <- winning_table |>
  filter_all(any_vars(is.na(.))) |>
  pull(municipality)

# filter for those municipalities to show the population varies +/- 100k
final_election |> 
  filter(municipality %in% varying_pop_municips) |> 
  group_by(municipality, date_elec, population) |> 
  summarise() |> 
  pivot_wider(names_from = date_elec, 
              values_from = population)
```
Now we will graph the results: 
```{r}
# Define custom colors for the given party abbreviations
party_colors <- c(
  "PSOE" = "#EF1C27",       # PARTIDO SOCIALISTA OBRERO ESPAÑOL
  "EAJ-PNV" = "#01796F",    # PARTIDO NACIONALISTA VASCO
  "ERC" = "#FFD700",        # ESQUERRA REPUBLICANA DE CATALUNYA
  "PODEMOS-IU" = "#5C2D91", # UNIDAS PODEMOS - IU
  "PP" = "#0454A3",         # PARTIDO POPULAR
  "VOX" = "#63BE21",        # VOX
  "CS" = "#EB6109",         # CIUDADANOS
  "BNG" = "#0093DD",        # BLOQUE NACIONALISTA GALLEGO
  "CIU" = "#FFB232",        # CONVERGÈNCIA I UNIÓ
  "EH-BILDU" = "#A6CE39",   # EH - BILDU
  "MP" = "#0CDCC3",         # MÁS PAÍS
  "Other" = "#808080"       # Other parties
)
```

```{r}
# Count the number of municipalities each party won in each election
library(forcats)

party_winners <- party_winners |> 
  mutate(party_grouped = fct_reorder(party_grouped, -num_municipalities)) 

ggplot(party_winners, aes(x = party_grouped, y = num_municipalities, fill = party_grouped)) +
  geom_bar(stat = "identity") + 
  facet_wrap(~ date_elec, scales = "free_y", ncol = 3) + 
  scale_fill_manual(values = party_colors, name = "Winning Party (Code)") + 
  labs(
    title = "Winning Parties in Municipalities with >100k Population",
    x = "Winning Party",
    y = "Number of Municipalities Won"
  ) +
  theme_minimal(base_size = 14) + 
  theme(
    axis.text.x = element_blank(), 
    axis.ticks.x = element_blank(),
    legend.position = "right", 
    legend.title = element_text(size = 12), 
    legend.text = element_text(size = 10), 
    strip.text = element_text(size = 12, face = "bold") 
  )
```


### 2. Which party was the second when the first was the PSOE? And when the first was the PP?

#### Identify the First and Second Parties

```{r}
ranked_parties <- final_election |> 
  group_by(date_elec, code_municipality) |> 
  arrange(desc(party_ballots)) |> 
  mutate(rank = row_number()) |> 
  filter(rank <= 2) |>  
  ungroup()
```

#### Filter when PSOE is first
```{r}
psoe_first <- ranked_parties |> 
  filter(rank == 1 & party_code == "PSOE") |> 
  left_join(ranked_parties |> filter(rank == 2), by = c("date_elec", "code_municipality")) |> 
  rename(
    first_party = party_code.x,  
    first_votes = party_ballots.x,  
    second_party = party_code.y,  
    second_votes = party_ballots.y,
    population = population.y
  ) |> 
  select(date_elec, code_municipality, population, first_party, first_votes, second_party, second_votes)
```

#### Filter when PP is first
```{r}
pp_first <- ranked_parties %>%
  filter(rank == 1 & party_code == "PP") %>%  
  left_join(ranked_parties %>% filter(rank == 2), by = c("date_elec", "code_municipality")) |> 
  rename(
    first_party = party_code.x,  
    first_votes = party_ballots.x,  
    second_party = party_code.y,  
    second_votes = party_ballots.y,
    population = population.y
  ) |> 
  select(date_elec, code_municipality, population, first_party, first_votes, second_party, second_votes)
```

#### Summarized PSOE first 
```{r}
psoe_summary <- psoe_first %>%
  group_by(date_elec, second_party) %>%
  summarise(
    total_votes = sum(second_votes),  
    count_as_second = n(),           
    .groups = "drop"
  ) %>%
  arrange(desc(date_elec)) 
print(psoe_summary)

psoe_summary_per_year <- psoe_first %>%
  group_by(date_elec) %>%                                
  filter(second_votes == max(second_votes)) %>%          
  select(date_elec, second_party) %>%      
  arrange(date_elec)  |> 
  print()
  
```
PP was the second party when PSOE was the winner in all the elections.

#### Summarized PP first 
```{r}
pp_summary <- pp_first %>%
  group_by(date_elec, second_party) %>%
  summarise(
    total_votes = sum(second_votes),  
    count_as_second = n(),           
    .groups = "drop"
  ) %>%
  arrange(desc(date_elec)) 
print(pp_summary)

pp_summary_per_year <- pp_first %>%
  group_by(date_elec) %>%                                
  filter(second_votes == max(second_votes)) %>%          
  select(date_elec, second_party) %>%      
  arrange(date_elec)  |> 
  print()
  
```
PSOE was the second party when PP was the winner in almost every election. PODEMOS-IU was the second party in the elections of 2015 and 2016 after PP.

#### Vis PSOE first 
```{r}
ggplot(psoe_first, aes(y = reorder(date_elec, desc(date_elec)), 
                     x = second_votes, fill = second_party)) +
  
  geom_bar(stat = "identity", position = "identity", width = 0.7) +
  scale_fill_manual(values = c("PP" = "#0157a1", "PODEMOS-IU" = "#663278", "VOX" = "#5AB531", "CS" = "#EB6109")) +
  scale_x_continuous(labels = scales::comma) + 
  theme_minimal() +
  labs(x="", y="", title= "Second party when the winner is PSOE", subtitle = "total n of votes per election") +
   theme(
    plot.title = element_text(face = "bold", size = 14, hjust = 0),
    plot.subtitle = element_text(face = "italic", size = 12, hjust = 0),
    legend.position = "bottom",
    legend.title=element_blank(),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.title = element_blank(),
    panel.grid.major.y = element_line(color = "gray", linetype = "dashed", size = 0.3)
  ) 
```
#### Second most voted party by population when the first id PSOE
```{r}
# Step 1: Create population categories with ordered factors
psoe_first <- psoe_first %>%
  mutate(
    population_category = factor(
      case_when(
        population < 10000 ~ "Pueblo Pequeño",
        population >= 10000 & population < 50000 ~ "Pueblo Mediano",
        population >= 50000 & population < 100000 ~ "Pueblo Grande",
        population >= 100000 & population < 500000 ~ "Ciudad Pequeña",
        population >= 500000 & population < 1000000 ~ "Gran Ciudad",
        population >= 1000000 ~ "Metrópolis"
      ),
      levels = c("Pueblo Pequeño", "Pueblo Mediano", "Pueblo Grande", 
                 "Ciudad Pequeña", "Gran Ciudad", "Metrópolis")
    )
  )

# Step 2: Loop through elections and create a plot for each election
unique_dates <- unique(psoe_first$date_elec)
plots <- list()

for (date in  unique_dates) {
  # Ensure `date` is treated as a valid Date object
  current_date <- as.Date(date)
  
  # Filter data for the specific election date
  data_filtered <- psoe_first %>%
    filter(date_elec == current_date) %>%
    group_by(population_category, second_party) %>%
    summarise(
      total_votes = sum(second_votes, na.rm = TRUE),
      .groups = "drop"
    )
  
  # Create the plot
  plot <- ggplot(data_filtered, aes(x = population_category, 
                                    y = total_votes, 
                                    fill = second_party)) +
    geom_bar(stat = "identity", position = "dodge", width = 0.7) +
    scale_fill_manual(values = c(
      "PP" = "#0157a1", 
      "PODEMOS-IU" = "#663278", 
      "VOX" = "#5AB531", 
      "CS" = "#EB6109"
    )) +
    scale_y_continuous(labels = scales::comma) + 
    labs(
      title = paste("Second Party by Population for Election on", format(current_date, "%Y-%m-%d")),  # Format the date properly
      x = "Population Category",
      y = "Total Votes"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
      axis.text.y = element_text(size = 10),
      legend.position = "bottom",
      legend.title = element_blank()  # Remove legend title
    )
  
  # Save the plot to the list
  plots[[as.character(current_date)]] <- plot
}

# Step 3: Display all plots (one at a time)
for (date in unique_dates) {
  print(plots[[as.character(as.Date(date))]])
}

```

#### Vis PP first 
```{r}
ggplot(pp_first, aes(y = reorder(date_elec, desc(date_elec)), 
                     x = second_votes, fill = second_party)) +
  
  geom_bar(stat = "identity", position = "identity", width = 0.7) +
  scale_fill_manual(values = c("PSOE" = "#f20400", "PODEMOS-IU" = "#663278", "VOX" = "#5AB531", "CS" = "#EB6109")) +
  scale_x_continuous(labels = scales::comma) + 
  theme_minimal() +
  labs(x="", y="", title= "Second party when the winner is PP", subtitle = "total n of votes per election") +
   theme(
    plot.title = element_text(face = "bold", size = 14, hjust = 0),
    plot.subtitle = element_text(face = "italic", size = 12, hjust = 0),
    legend.position = "bottom",
    legend.title=element_blank(),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10),
    axis.title = element_blank(),
    panel.grid.major.y = element_line(color = "gray", linetype = "dashed", size = 0.3)
  ) 
```
#### Second most voted party by population when the first id PSOE
```{r}
# Step 1: Create population categories with ordered factors for PP
pp_first <- pp_first %>%
  mutate(
    population_category = factor(
      case_when(
        population < 10000 ~ "Pueblo Pequeño",
        population >= 10000 & population < 50000 ~ "Pueblo Mediano",
        population >= 50000 & population < 100000 ~ "Pueblo Grande",
        population >= 100000 & population < 500000 ~ "Ciudad Pequeña",
        population >= 500000 & population < 1000000 ~ "Gran Ciudad",
        population >= 1000000 ~ "Metrópolis"
      ),
      levels = c("Pueblo Pequeño", "Pueblo Mediano", "Pueblo Grande", 
                 "Ciudad Pequeña", "Gran Ciudad", "Metrópolis")
    )
  )

# Step 2: Loop through elections and create a plot for each election for PP
unique_dates_pp <- unique(pp_first$date_elec)
plots <- list()

# Create a list to store plots for PP
plots_pp <- list()

for (date in unique_dates_pp) {
  # Ensure `date` is treated as a valid Date object
  current_date <- as.Date(date)
  
  # Filter data for the specific election date
  data_filtered <- pp_first %>%
    filter(date_elec == current_date) %>%
    group_by(population_category, second_party) %>%
    summarise(
      total_votes = sum(second_votes, na.rm = TRUE),
      .groups = "drop"
    )
  
  # Create the plot
  plot <- ggplot(data_filtered, aes(x = population_category, 
                                    y = total_votes, 
                                    fill = second_party)) +
    geom_bar(stat = "identity", position = "dodge", width = 0.7) +
    scale_fill_manual(values = c(
      "PSOE" = "#f20400", 
      "PODEMOS-IU" = "#663278", 
      "VOX" = "#5AB531", 
      "CS" = "#EB6109"
    )) +
    scale_y_continuous(labels = scales::comma) + 
    labs(
      title = paste("Second Party by Population for Election on", format(current_date, "%Y-%m-%d")),  # Format the date properly
      x = "Population Category",
      y = "Total Votes"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
      axis.text.y = element_text(size = 10),
      legend.position = "bottom",
      legend.title = element_blank()  # Remove legend title
    )
  
  # Save the plot to the list
  plots_pp[[as.character(current_date)]] <- plot
}

# Step 3: Display all plots for PP (one at a time)
for (date in unique_dates_pp) {
  print(plots_pp[[as.character(as.Date(date))]])
}
```

### 3. Who benefits from low turnout?

```{r}

```

### 4. How to analyze the relationship between census and vote? Is it true that certain parties win in rural areas?

```{r}

```

### 5. How to calibrate the error of the polls (remember that the polls are voting intentions at national level)?

```{r}
survey_q5 <- final_surveys |> 
  summarise(avg_voting_intention = mean(votes), .by = c(date_elec, party_code))

# The means do not add up to 1 (sum surveys just do not add up to 1)
# survey_q5 |> 
#   summarise(sum(avg_vote), .by = date_elec)

election_q5 <- final_election |>
  summarise(party_votes = sum(party_ballots), .by = c(date_elec, party_code))

turnout_q5 <- turnout |> 
  summarise(tot_votes = sum(total_votes), 
            valid_votes = sum(valid_votes + blank_votes), 
            null_votes = sum(null_votes),
            tot_pop = sum(population),
            .by = c(date_elec)) |> 
  mutate(turnout = (tot_votes/tot_pop)*100)

election_q5 <- election_q5 |> 
  left_join(turnout_q5, by = join_by(date_elec)) |> 
  mutate(share_votes = (party_votes/valid_votes)*100)

final_q5 <- survey_q5 |> 
  left_join(election_q5, by = join_by(date_elec, party_code)) |> 
  select(-tot_votes, -tot_pop, -party_votes) |> 
  mutate(polling_error = avg_voting_intention - share_votes)

polling_err <- final_q5 |> 
  summarise(avg_err = mean(polling_error), .by = party_code)

ggplot(polling_err, aes(x = reorder(party_code, avg_err), y = avg_err, fill = factor(party_code))) +
  geom_bar(stat = "identity") +  
  scale_fill_manual(values = party_colors) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Polling Error by Political Party",
    subtitle = "Average polling error for elections between 2008 and 2019 by main political party",
    x = "Party",
    # y = "Average Polling Error")
    y = paste("\u2190 Underestimated", strrep(" ", 35), "Overestimated \u2192")) +
  scale_y_continuous(limits = c(-7,5), 
                     expand = expansion(add = c(0,0)),
                     breaks = c(-6, -4, -2, 0, 2, 4)) +
  theme_minimal() +
  theme(
    legend.position = NULL,
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.text.x = element_text(size = 5), 
    panel.grid.minor = element_blank(),
    axis.title.y = element_text(size = 8)) +
  guides(fill = guide_legend(title = "Political Party"))
```

Bigger party might be subject to bigger errors because they are voted by more people (ex. PNV cannot be over/underestimated by several percentage points as it only receives 1% of votes)
```

### 6. Which polling houses got it right the most and which ones deviated the most from the results?

```{r}

```

## Additional questions

Confirm with the group your original analysis question to avoid clashing ideas :)

SOME IDEAS FOR THE ORIGINAL QUESTIONS TO START?

-   Which regions had the most predictable votes (i.e. consistently voted for the same party) and which regions were the most undecided (i.e. had the most variance in there votes across) between the 2008 and 2019 elections?

- ✅ Map the outcomes over time - plotly on the results? Isabel has some interest but tbc if we will Map.

-   Can we load in other data? think that would go down well? Maybe predict the next election results based on previous trends of the 5 years and compare to see if the following election followed the trend? Think Javi would be happy with new data.

-   Which municipalities voting patterns were most consistent with the national trends?

-   Which 2 media/pollster outlets had the most polarized estimates of each election?

### 7. Jacklyn and Linghan

```{r}

```

### 8.

```{r}

```

### 9. How has electoral support for smaller parties evolved over time?

The maps show a significant increase in support for smaller parties over time by autonomous community, with darker regions indicating higher percentages. Madrid, for example, rises from around 10% in 2008 to a peak of 54% in April 2019. Northern communities including Catalonia, Navarra, and the Basque Country consistently show high levels of support for small parties.

The April 2019 election marked the height of support for smaller parties overall, but the November 2019 election, a re-vote triggered by the failure to form a majority coalition, shows a slight decline in their support, as reflected in the lighter shading across many regions. 

```{r small-parties}
# Load necessary libraries
library(mapSpain)
library(sf)
library(ggplot2)
library(dplyr)
library(ggiraph)

# Calculate % (PSOE + PP) and % other parties for each community and date
party_percentage <- final_election |> 
  group_by(code_community, date_elec) |> 
  summarize(
    total_votes = sum(party_ballots, na.rm = TRUE),
    PSOE_PP_votes = sum(party_ballots[party_code %in% c("PSOE", "PP")], na.rm = TRUE),
    other_votes = total_votes - PSOE_PP_votes
  ) |> 
  mutate(
    PSOE_PP_percent = (PSOE_PP_votes / total_votes) * 100,
    other_percent = (other_votes / total_votes) * 100
  ) |> 
  ungroup()

# Get map and simplify geometry
spain_map <- esp_get_ccaa() |> 
  st_simplify(dTolerance = 0.01)

# Community mapping with names
community_map <- tibble(
  code_community = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12", "13", "14", "15", "16", "17"),
  codauto = c("01", "02", "03", "04", "05", "06", "08", "07", "09", "11", "12", "13", "15", "16", "14", "17", "10"),
  community_name = c(
    "Andalusia", "Aragon", "Asturias", "Balearic Islands", "Canary Islands", "Cantabria",
    "Castile and Leon", "Castile-La Mancha", "Catalonia", "Extremadura", "Galicia",
    "Madrid", "Navarra", "Basque Country", "Murcia", "La Rioja", "Valencia"
  )
)

# Add codauto and community names to your electoral data
party_percentage <- party_percentage |> 
  left_join(community_map, by = "code_community")

# Merge spatial data with electoral data using codauto
map_data <- spain_map |> 
  left_join(party_percentage, by = "codauto") |> 
  drop_na(date_elec)

# Create the ggplot map
gg_map <- ggplot(map_data) +
  geom_sf_interactive(
    aes(
      fill = other_percent, # Correct fill variable
      geometry = geometry,
      tooltip = paste(
        "Region: ", community_name,
        "<br>% Other Votes: ", round(other_percent, 2), "%"
      ),
      data_id = codauto
    ),
    color = "white"
  ) +
  facet_wrap(~ date_elec) +
  scale_fill_gradient(low = "white", high = "darkblue", name = "% Other Votes") +
  labs(
    title = "Trends in Electoral Support for Non-Major Parties by Region",
    subtitle = "Where 'Other' Excludes PP and PSOE",
    fill = "% Other Votes"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    strip.text = element_text(size = 8)
  )

# Convert ggplot to an interactive plot with ggiraph
interactive_map <- girafe(
  ggobj = gg_map,
  width_svg = 10,
  height_svg = 6
)

# Optional: Adjust tooltip style
interactive_map <- interactive_map |> 
  girafe_options(
    opts_tooltip(css = "background-color: white; color: black; border: 1px solid black; padding: 5px;"),
    opts_hover(css = "fill: red")
  )

# Display the interactive map
interactive_map

```

